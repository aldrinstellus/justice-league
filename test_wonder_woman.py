#!/usr/bin/env python3
"""
âš¡ WONDER WOMAN ACCESSIBILITY - Test Suite
===========================================

Tests for comprehensive accessibility testing with WCAG 2.2 compliance.

Author: Justice League
Created: October 23, 2025
"""

import sys
import os
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from core.justice_league.wonder_woman_accessibility import WonderWomanAccessibility


def test_wonder_woman_initialization():
    """Test 1: Wonder Woman Accessibility initialization."""
    print("\n" + "=" * 70)
    print("Test 1: Wonder Woman Accessibility Initialization")
    print("=" * 70)

    ww = WonderWomanAccessibility()

    assert ww is not None, "Wonder Woman should initialize"
    assert hasattr(ww, 'champion_accessibility_analysis'), "Should have champion_accessibility_analysis method"
    assert hasattr(ww, 'world_class_analyzer'), "Should have world_class_analyzer"
    assert hasattr(ww, '_calculate_champion_score'), "Should have _calculate_champion_score method"
    assert hasattr(ww, '_generate_battle_plan'), "Should have _generate_battle_plan method"

    print("âœ… PASSED: Wonder Woman initialized successfully")
    print(f"   axe-core enabled: {ww.axe_enabled}")
    print(f"   colormath enabled: {ww.colormath_enabled}")
    print(f"   Playwright enabled: {ww.playwright_enabled}")
    return True


def test_hex_to_rgb_conversion():
    """Test 2: Hex to RGB color conversion."""
    print("\n" + "=" * 70)
    print("Test 2: Hex to RGB Color Conversion")
    print("=" * 70)

    ww = WonderWomanAccessibility()

    # Test various hex colors
    test_cases = [
        ("#FFFFFF", (255, 255, 255)),  # White
        ("#000000", (0, 0, 0)),        # Black
        ("#FF0000", (255, 0, 0)),      # Red
        ("#00FF00", (0, 255, 0)),      # Green
        ("#0000FF", (0, 0, 255)),      # Blue
        ("FFFFFF", (255, 255, 255)),   # White without #
    ]

    for hex_color, expected_rgb in test_cases:
        rgb = ww._hex_to_rgb(hex_color)
        assert rgb == expected_rgb, f"Hex {hex_color} should convert to {expected_rgb}, got {rgb}"

    print(f"âœ… PASSED: Hex to RGB conversion works for {len(test_cases)} test cases")
    return True


def test_wcag_contrast_calculation():
    """Test 3: WCAG contrast ratio calculation."""
    print("\n" + "=" * 70)
    print("Test 3: WCAG Contrast Ratio Calculation")
    print("=" * 70)

    ww = WonderWomanAccessibility()

    # Test contrast ratios
    # White on black should be maximum contrast (21:1)
    white = (255, 255, 255)
    black = (0, 0, 0)
    contrast_wb = ww._calculate_wcag_contrast(white, black)
    assert contrast_wb == 21.0, f"White on black should have 21:1 contrast, got {contrast_wb}"

    # Same color should be minimum contrast (1:1)
    contrast_same = ww._calculate_wcag_contrast(white, white)
    assert contrast_same == 1.0, f"Same colors should have 1:1 contrast, got {contrast_same}"

    # Test WCAG AA threshold (4.5:1 for normal text)
    # Gray #767676 on white has ~4.5:1 contrast
    gray = (118, 118, 118)
    contrast_gray = ww._calculate_wcag_contrast(gray, white)
    assert 4.4 < contrast_gray < 4.6, f"Gray on white should have ~4.5:1 contrast, got {contrast_gray}"

    print(f"âœ… PASSED: WCAG contrast calculation works correctly")
    print(f"   White on Black: {contrast_wb}:1")
    print(f"   Same Color: {contrast_same}:1")
    print(f"   Gray on White: {contrast_gray:.2f}:1")
    return True


def test_champion_score_calculation():
    """Test 4: Wonder Woman Champion score calculation."""
    print("\n" + "=" * 70)
    print("Test 4: Wonder Woman Champion Score Calculation")
    print("=" * 70)

    ww = WonderWomanAccessibility()

    # Mock high-quality results with multiple tools
    high_quality_results = {
        'tools_used': ['WCAG 2.2 Analyzer', 'axe-core', 'colormath', 'Playwright', 'Browser Eyes'],
        'analyses': {
            'wcag_22_analysis': {
                'scores': {
                    'overall_score': 92.0,
                    'wcag_a_score': 95.0,
                    'wcag_aa_score': 90.0,
                    'wcag_aaa_score': 88.0
                }
            }
        }
    }

    score_high = ww._calculate_champion_score(high_quality_results)

    assert score_high['overall_score'] >= 90, f"High quality should score >= 90, got {score_high['overall_score']}"
    assert score_high['base_wcag_score'] == 92.0, "Base WCAG score should be 92.0"
    assert score_high['tool_coverage_bonus'] == 10, f"5 tools should give 10 point bonus, got {score_high['tool_coverage_bonus']}"
    assert score_high['tools_used_count'] == 5, f"Should count 5 tools, got {score_high['tools_used_count']}"
    assert 'S' in score_high['grade'] or 'A' in score_high['grade'], f"Should get S or A grade, got {score_high['grade']}"
    assert 'wonder_woman_verdict' in score_high, "Should have wonder_woman_verdict"

    # Mock low-quality results with few tools
    low_quality_results = {
        'tools_used': ['WCAG 2.2 Analyzer'],
        'analyses': {
            'wcag_22_analysis': {
                'scores': {
                    'overall_score': 60.0
                }
            }
        }
    }

    score_low = ww._calculate_champion_score(low_quality_results)
    assert score_low['overall_score'] < 75, f"Low quality should score < 75, got {score_low['overall_score']}"

    print(f"âœ… PASSED: Champion Score calculation works")
    print(f"   High Quality Score: {score_high['overall_score']}/100 ({score_high['grade']})")
    print(f"   Low Quality Score:  {score_low['overall_score']}/100 ({score_low['grade']})")
    return True


def test_battle_plan_generation():
    """Test 5: Wonder Woman battle plan generation."""
    print("\n" + "=" * 70)
    print("Test 5: Wonder Woman Battle Plan Generation")
    print("=" * 70)

    ww = WonderWomanAccessibility()

    # Mock issues with different severities
    mock_issues = [
        {'component_id': 'btn1', 'title': 'Missing alt text', 'severity': 'critical'},
        {'component_id': 'btn2', 'title': 'Low contrast', 'severity': 'critical'},
        {'component_id': 'btn3', 'title': 'Missing ARIA label', 'severity': 'serious'},
        {'component_id': 'btn4', 'title': 'Keyboard navigation', 'severity': 'serious'},
        {'component_id': 'btn5', 'title': 'Focus indicator', 'severity': 'serious'},
        {'component_id': 'btn6', 'title': 'Touch target size', 'severity': 'moderate'},
        {'component_id': 'btn7', 'title': 'Color alone', 'severity': 'moderate'},
    ]

    battle_plan = ww._generate_battle_plan(mock_issues)

    assert 'immediate_action_required' in battle_plan, "Battle plan should have immediate_action_required"
    assert battle_plan['immediate_action_required'] == 2, f"Should have 2 critical issues, got {battle_plan['immediate_action_required']}"
    assert battle_plan['high_priority'] == 3, f"Should have 3 serious issues, got {battle_plan['high_priority']}"
    assert battle_plan['medium_priority'] == 2, f"Should have 2 moderate issues, got {battle_plan['medium_priority']}"

    assert 'battle_phases' in battle_plan, "Battle plan should have battle_phases"
    assert 'phase_1_critical_strike' in battle_plan['battle_phases'], "Should have phase 1"
    assert 'phase_2_warrior_assault' in battle_plan['battle_phases'], "Should have phase 2"
    assert 'phase_3_strategic_advance' in battle_plan['battle_phases'], "Should have phase 3"

    assert 'estimated_effort' in battle_plan, "Battle plan should have estimated_effort"
    assert 'wonder_woman_strategy' in battle_plan, "Battle plan should have wonder_woman_strategy"

    print(f"âœ… PASSED: Battle plan generated successfully")
    print(f"   Critical: {battle_plan['immediate_action_required']}")
    print(f"   Serious: {battle_plan['high_priority']}")
    print(f"   Moderate: {battle_plan['medium_priority']}")
    return True


def test_battle_effort_estimation():
    """Test 6: Wonder Woman battle effort estimation."""
    print("\n" + "=" * 70)
    print("Test 6: Wonder Woman Battle Effort Estimation")
    print("=" * 70)

    ww = WonderWomanAccessibility()

    # Test different issue counts
    test_cases = [
        (0, 'Victory!'),
        (5, 'Light Skirmish'),
        (15, 'Medium Battle'),
        (35, 'Major Campaign'),
        (75, 'Epic War'),
    ]

    for issue_count, expected_level in test_cases:
        mock_issues = [{'id': f'issue_{i}'} for i in range(issue_count)]
        effort = ww._estimate_battle_effort(mock_issues)

        assert 'level' in effort, "Effort should have level"
        assert 'hours' in effort, "Effort should have hours"
        assert 'days' in effort, "Effort should have days"
        assert 'wonder_woman_says' in effort, "Effort should have wonder_woman_says"
        assert effort['level'] == expected_level, f"Expected {expected_level}, got {effort['level']}"

    print(f"âœ… PASSED: Battle effort estimation works for {len(test_cases)} scenarios")
    return True


def test_combine_all_issues():
    """Test 7: Wonder Woman combine and deduplicate issues."""
    print("\n" + "=" * 70)
    print("Test 7: Combine and Deduplicate Issues")
    print("=" * 70)

    ww = WonderWomanAccessibility()

    # Mock analyses with duplicate issues
    mock_analyses = {
        'wcag_22_analysis': {
            'all_issues': [
                {'component_id': 'btn1', 'title': 'Missing alt text', 'severity': 'critical'},
                {'component_id': 'btn2', 'title': 'Low contrast', 'severity': 'serious'},
                {'component_id': 'btn1', 'title': 'Missing alt text', 'severity': 'critical'},  # Duplicate!
                {'component_id': 'btn3', 'title': 'ARIA label', 'severity': 'moderate'},
            ]
        }
    }

    combined = ww._combine_all_issues(mock_analyses)

    # Should deduplicate btn1 "Missing alt text"
    assert len(combined) == 3, f"Should have 3 unique issues (deduplicated), got {len(combined)}"

    # Check for unique component_id + title combinations
    seen_keys = set()
    for issue in combined:
        key = (issue['component_id'], issue['title'])
        assert key not in seen_keys, f"Duplicate issue found: {key}"
        seen_keys.add(key)

    print(f"âœ… PASSED: Combined and deduplicated {len(combined)} unique issues from 4 total")
    return True


def test_lasso_of_truth():
    """Test 8: Wonder Woman's Lasso of Truth (axe-core)."""
    print("\n" + "=" * 70)
    print("Test 8: Wonder Woman's Lasso of Truth (axe-core)")
    print("=" * 70)

    ww = WonderWomanAccessibility()

    # Test Lasso of Truth structure (mocked)
    result = ww._wield_lasso_of_truth("/tmp/test.html")

    assert 'status' in result, "Result should have status"
    assert 'tool' in result or 'message' in result, "Result should have tool or message"

    if ww.axe_enabled:
        assert result['status'] == 'ready', "axe should be ready if enabled"
        assert 'Lasso of Truth' in result['tool'], "Tool should mention Lasso of Truth"
        assert 'capabilities' in result, "Should list capabilities"
        assert 'rules_checked' in result, "Should list rules checked"
        assert 'wonder_woman_verdict' in result, "Should have Wonder Woman's verdict"
    else:
        assert result['status'] == 'disabled', "axe should be disabled if not installed"

    print(f"âœ… PASSED: Lasso of Truth structure validated")
    print(f"   Status: {result['status']}")
    return True


def test_bracers_color_analysis():
    """Test 9: Wonder Woman's Bracers (color analysis)."""
    print("\n" + "=" * 70)
    print("Test 9: Wonder Woman's Bracers (Color Analysis)")
    print("=" * 70)

    ww = WonderWomanAccessibility()

    # Mock design data with color pairs
    mock_design_data = {
        'components': {
            'btn1': {
                'foreground_color': '#000000',  # Black
                'background_color': '#FFFFFF'   # White (good contrast)
            },
            'btn2': {
                'foreground_color': '#FF0000',  # Red
                'background_color': '#FFA500'   # Orange (low Delta E - too similar!)
            },
            'btn3': {
                'foreground_color': '#0000FF',  # Blue
                'background_color': '#FFFFFF'   # White (good contrast)
            }
        }
    }

    result = ww._analyze_colors_with_bracers(mock_design_data)

    assert 'status' in result, "Result should have status"

    if ww.colormath_enabled:
        assert result['status'] == 'active', "colormath should be active if enabled"
        assert 'color_pairs_analyzed' in result, "Should count color pairs analyzed"
        assert result['color_pairs_analyzed'] == 3, f"Should analyze 3 pairs, got {result['color_pairs_analyzed']}"
        assert 'recommendations' in result, "Should have recommendations"
        assert 'wonder_woman_verdict' in result, "Should have Wonder Woman's verdict"
    else:
        assert result['status'] == 'disabled', "colormath should be disabled if not installed"

    print(f"âœ… PASSED: Bracers color analysis structure validated")
    print(f"   Status: {result['status']}")
    return True


def test_full_champion_analysis():
    """Test 10: Full Wonder Woman Champion accessibility analysis."""
    print("\n" + "=" * 70)
    print("Test 10: Full Wonder Woman Champion Analysis")
    print("=" * 70)

    ww = WonderWomanAccessibility()

    # Mock comprehensive design data
    mock_design_data = {
        'components': {
            'btn1': {
                'id': 'submit-button',
                'type': 'button',
                'text': 'Submit',
                'foreground_color': '#FFFFFF',
                'background_color': '#007BFF',
                'has_aria_label': False,  # Accessibility issue!
                'contrast_ratio': 5.2
            },
            'img1': {
                'id': 'hero-image',
                'type': 'image',
                'alt_text': '',  # Missing! Critical issue
                'foreground_color': None,
                'background_color': None
            }
        }
    }

    # Run full champion analysis
    result = ww.champion_accessibility_analysis(mock_design_data, html_output_path=None)

    # Validate top-level structure
    assert result['champion_mode'] == True, "Should be in champion mode"
    assert result['hero'] == 'âš¡ Wonder Woman - Accessibility Champion', "Should identify as Wonder Woman"
    assert 'tools_used' in result, "Should list tools used"
    assert len(result['tools_used']) > 0, "Should use at least one tool"

    # Validate analyses
    assert 'analyses' in result, "Should have analyses"
    assert 'wcag_22_analysis' in result['analyses'], "Should have WCAG 2.2 analysis"

    # Validate combined issues
    assert 'combined_issues' in result, "Should have combined_issues"

    # Validate champion score
    assert 'champion_score' in result, "Should have champion_score"
    champion_score = result['champion_score']
    assert 'overall_score' in champion_score, "Champion score should have overall_score"
    assert 0 <= champion_score['overall_score'] <= 100, f"Score should be 0-100, got {champion_score['overall_score']}"
    assert 'grade' in champion_score, "Champion score should have grade"
    assert 'wonder_woman_verdict' in champion_score, "Champion score should have verdict"

    # Validate battle plan
    assert 'battle_plan' in result, "Should have battle_plan"
    battle_plan = result['battle_plan']
    assert 'battle_phases' in battle_plan, "Battle plan should have phases"
    assert 'estimated_effort' in battle_plan, "Battle plan should have effort estimate"

    print(f"\nâœ… PASSED: Full champion analysis successful")
    print(f"   Tools Used: {len(result['tools_used'])}")
    print(f"   Champion Score: {champion_score['overall_score']}/100")
    print(f"   Grade: {champion_score['grade']}")
    print(f"   Combined Issues: {len(result['combined_issues'])}")
    return True


def run_all_tests():
    """Run complete test suite."""
    print("\nâš¡ Wonder Woman Accessibility - Test Suite")
    print("=" * 70)
    print("Testing Comprehensive Accessibility Analysis with WCAG 2.2")
    print("=" * 70)

    tests = [
        ("Initialization", test_wonder_woman_initialization),
        ("Hex to RGB Conversion", test_hex_to_rgb_conversion),
        ("WCAG Contrast Calculation", test_wcag_contrast_calculation),
        ("Champion Score Calculation", test_champion_score_calculation),
        ("Battle Plan Generation", test_battle_plan_generation),
        ("Battle Effort Estimation", test_battle_effort_estimation),
        ("Combine and Deduplicate Issues", test_combine_all_issues),
        ("Lasso of Truth (axe-core)", test_lasso_of_truth),
        ("Bracers Color Analysis", test_bracers_color_analysis),
        ("Full Champion Analysis", test_full_champion_analysis),
    ]

    passed = 0
    failed = 0
    errors = []

    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
        except AssertionError as e:
            failed += 1
            errors.append(f"{test_name}: {str(e)}")
            print(f"\nâŒ FAILED: {test_name}")
            print(f"   Error: {str(e)}")
        except Exception as e:
            failed += 1
            errors.append(f"{test_name}: {str(e)}")
            print(f"\nâŒ ERROR: {test_name}")
            print(f"   Error: {str(e)}")

    # Summary
    print("\n" + "=" * 70)
    print("Test Suite Summary")
    print("=" * 70)
    print(f"Total Tests: {len(tests)}")
    print(f"âœ… Passed: {passed}")
    print(f"âŒ Failed: {failed}")

    if errors:
        print(f"\nâŒ Errors:")
        for error in errors:
            print(f"   - {error}")

    success_rate = (passed / len(tests)) * 100
    print(f"\nSuccess Rate: {success_rate:.1f}%")

    if success_rate == 100:
        print("\nðŸŽ‰ ALL TESTS PASSED! Wonder Woman's Lasso reveals perfect accessibility testing!")
        print("âš¡ With the power of truth, all barriers are revealed!")
        return 0
    else:
        print(f"\nâš ï¸  {failed} test(s) failed. Please review.")
        return 1


if __name__ == '__main__':
    sys.exit(run_all_tests())
