"""
ğŸŒ³ TEST GIT WORKTREES - PARALLEL HERO OPERATIONS
Demonstrates Superman's parallel deployment capabilities with git worktrees

Tests:
1. GitWorktreeManager functionality
2. Parallel hero deployment with isolated workspaces
3. Performance comparison: parallel vs sequential
4. Cleanup and resource management

Version: 1.0.0
Created: 2025-10-31
"""

import sys
import time
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from core.utils.git_worktree_manager import GitWorktreeManager, HeroWorktreeContext
from core.justice_league.superman_coordinator import SupermanCoordinator


def test_worktree_manager():
    """Test 1: GitWorktreeManager basic functionality"""
    print("\n" + "="*80)
    print("TEST 1: GitWorktreeManager Basic Functionality")
    print("="*80)

    manager = GitWorktreeManager()

    # Test worktree creation
    print("\nğŸŒ³ Creating test worktree...")
    worktree_info = manager.create_worktree("test-task", branch="main")

    print(f"  âœ… Worktree created: {worktree_info['path']}")
    print(f"  ğŸ“‹ Branch: {worktree_info['branch']}")
    print(f"  ğŸ•’ Created: {worktree_info['created_at']}")

    # Test worktree listing
    print("\nğŸŒ³ Listing all worktrees...")
    all_worktrees = manager.list_worktrees()
    print(f"  ğŸ“Š Found {len(all_worktrees)} worktrees")
    for wt in all_worktrees:
        print(f"     â€¢ {wt.get('path')} ({wt.get('branch', 'N/A')})")

    # Test worktree status
    print("\nğŸŒ³ Checking worktree status...")
    status = manager.get_worktree_status(Path(worktree_info['path']))
    print(f"  âœ… Status: {'clean' if status.get('clean') else 'has changes'}")

    # Test cleanup
    print("\nğŸŒ³ Cleaning up test worktree...")
    success = manager.remove_worktree(Path(worktree_info['path']))
    print(f"  {'âœ…' if success else 'âŒ'} Cleanup: {'successful' if success else 'failed'}")

    return True


def test_context_manager():
    """Test 2: HeroWorktreeContext manager"""
    print("\n" + "="*80)
    print("TEST 2: HeroWorktreeContext Manager")
    print("="*80)

    manager = GitWorktreeManager()

    print("\nğŸŒ³ Using context manager for automatic cleanup...")

    with HeroWorktreeContext(manager, "context-test") as worktree:
        print(f"  âœ… Worktree created: {worktree['path']}")
        print(f"  ğŸ“‹ Task: {worktree['task_name']}")
        print("  ğŸ”¨ Simulating work in worktree...")
        time.sleep(0.5)

    print("  âœ… Context manager auto-cleaned up worktree")

    return True


def test_parallel_hero_deployment():
    """Test 3: Superman parallel deployment with worktrees"""
    print("\n" + "="*80)
    print("TEST 3: Superman Parallel Hero Deployment")
    print("="*80)

    superman = SupermanCoordinator()

    # Define parallel missions (simulated)
    missions = [
        {
            'hero_name': 'oracle',
            'task_name': 'analyze-pattern-1',
            'params': {
                'file_key': 'test-key-1'
            }
        },
        {
            'hero_name': 'oracle',
            'task_name': 'analyze-pattern-2',
            'params': {
                'file_key': 'test-key-2'
            }
        },
        {
            'hero_name': 'oracle',
            'task_name': 'analyze-pattern-3',
            'params': {
                'file_key': 'test-key-3'
            }
        }
    ]

    print(f"\nğŸ¦¸ Deploying {len(missions)} heroes in parallel...")
    print(f"  ğŸŒ³ Using git worktrees for isolation")
    print(f"  âš¡ Max workers: 4")

    start_time = time.time()

    # Execute parallel deployment
    results = superman.deploy_heroes_parallel(
        missions=missions,
        max_workers=4,
        use_worktrees=True
    )

    duration = time.time() - start_time

    # Display results
    print(f"\nğŸ“Š Parallel Deployment Results:")
    print(f"  Total missions: {results['total_missions']}")
    print(f"  âœ… Successful: {results['successful']}")
    print(f"  âŒ Failed: {results['failed']}")
    print(f"  â±ï¸  Duration: {duration:.2f}s")
    print(f"  ğŸŒ³ Used worktrees: {results['used_worktrees']}")

    if results.get('worktree_cleanup'):
        cleanup = results['worktree_cleanup']
        print(f"\nğŸ§¹ Worktree Cleanup:")
        print(f"  âœ… Removed: {cleanup['success']}")
        print(f"  âŒ Failed: {cleanup['failures']}")

    return results['successful'] == len(missions)


def test_performance_comparison():
    """Test 4: Compare parallel vs sequential performance"""
    print("\n" + "="*80)
    print("TEST 4: Performance Comparison - Parallel vs Sequential")
    print("="*80)

    superman = SupermanCoordinator()

    # Test missions
    test_missions = [
        {
            'hero_name': 'oracle',
            'task_name': f'perf-test-{i}',
            'params': {'file_key': f'test-{i}'}
        }
        for i in range(6)
    ]

    # Test 1: Parallel execution
    print("\nâš¡ Running parallel execution...")
    start_parallel = time.time()

    parallel_results = superman.deploy_heroes_parallel(
        missions=test_missions,
        max_workers=4,
        use_worktrees=True
    )

    parallel_duration = time.time() - start_parallel

    # Test 2: Sequential execution (simulated by max_workers=1)
    print("\nğŸ¢ Running sequential execution...")
    start_sequential = time.time()

    sequential_results = superman.deploy_heroes_parallel(
        missions=test_missions,
        max_workers=1,
        use_worktrees=False
    )

    sequential_duration = time.time() - start_sequential

    # Performance analysis
    print("\nğŸ“Š Performance Analysis:")
    print(f"  Parallel execution:   {parallel_duration:.2f}s")
    print(f"  Sequential execution: {sequential_duration:.2f}s")

    speedup = sequential_duration / parallel_duration if parallel_duration > 0 else 0
    print(f"  âš¡ Speedup: {speedup:.2f}x")

    # Efficiency analysis
    if speedup > 1.5:
        print(f"  âœ… EXCELLENT: {speedup:.1f}x speedup with parallel processing")
    elif speedup > 1.0:
        print(f"  âœ… GOOD: {speedup:.1f}x speedup achieved")
    else:
        print(f"  âš ï¸  No speedup - tasks may be too simple or overhead too high")

    return speedup > 1.0


def test_worktree_cleanup_and_pruning():
    """Test 5: Cleanup and orphan detection"""
    print("\n" + "="*80)
    print("TEST 5: Cleanup and Orphan Detection")
    print("="*80)

    manager = GitWorktreeManager()

    # Create some test worktrees
    print("\nğŸŒ³ Creating test worktrees...")
    test_worktrees = []
    for i in range(3):
        wt = manager.create_worktree(f"cleanup-test-{i}")
        test_worktrees.append(wt)
        print(f"  âœ… Created: {wt['path']}")

    # Test cleanup_all
    print("\nğŸ§¹ Cleaning up all worktrees...")
    cleanup_result = manager.cleanup_all(force=True)

    print(f"  ğŸ“Š Cleanup summary:")
    print(f"     Total: {cleanup_result['total']}")
    print(f"     âœ… Success: {cleanup_result['success']}")
    print(f"     âŒ Failures: {cleanup_result['failures']}")

    # Test pruning
    print("\nğŸŒ³ Pruning orphaned worktrees...")
    pruned_count = manager.prune_orphaned()
    print(f"  ğŸ“Š Pruned {pruned_count} orphaned worktrees")

    return cleanup_result['success'] == cleanup_result['total']


def run_all_tests():
    """Run all git worktree tests"""
    print("\n" + "="*80)
    print("ğŸŒ³ GIT WORKTREES - PARALLEL HERO OPERATIONS TEST SUITE")
    print("="*80)

    results = {
        'total': 0,
        'passed': 0,
        'failed': 0
    }

    tests = [
        ("GitWorktreeManager Basic Functionality", test_worktree_manager),
        ("HeroWorktreeContext Manager", test_context_manager),
        ("Parallel Hero Deployment", test_parallel_hero_deployment),
        ("Performance Comparison", test_performance_comparison),
        ("Cleanup and Pruning", test_worktree_cleanup_and_pruning)
    ]

    for test_name, test_func in tests:
        results['total'] += 1
        try:
            print(f"\nRunning: {test_name}...")
            success = test_func()

            if success:
                results['passed'] += 1
                print(f"  âœ… PASSED: {test_name}")
            else:
                results['failed'] += 1
                print(f"  âŒ FAILED: {test_name}")

        except Exception as e:
            results['failed'] += 1
            print(f"  âŒ ERROR: {test_name}")
            print(f"     {str(e)}")

    # Final summary
    print("\n" + "="*80)
    print("TEST SUMMARY")
    print("="*80)
    print(f"Total tests: {results['total']}")
    print(f"âœ… Passed: {results['passed']}")
    print(f"âŒ Failed: {results['failed']}")
    print(f"Success rate: {(results['passed']/results['total']*100):.1f}%")

    print("\nğŸŒ³ Git Worktrees Integration: " +
          ("âœ… READY FOR PRODUCTION" if results['failed'] == 0 else "âš ï¸  NEEDS ATTENTION"))

    return results['failed'] == 0


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
